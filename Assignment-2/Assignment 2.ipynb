{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 01: Import Spark Session and initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entry points to spark\n",
    "from pyspark import SparkContext # Spark\n",
    "from pyspark.sql import SparkSession # Spark SQL\n",
    "\n",
    "# We add this line to avoid an error : \"Cannot run multiple SparkContexts at once\". \n",
    "# If there is an existing spark context, we will reuse it instead of creating a new context.\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# local[4]: run Spark locally with 4 working processors as logical cores on your machine.\n",
    "# In the field of `master`, we use a local server with as many working processors (or threads) as possible (i.e. `local[4]`). \n",
    "# If we want Spark to run locally with 'k' worker threads, we can specify as `local[k]`.\n",
    "# The `appName` field is a name to be shown on the Sparking cluster UI. \n",
    "\n",
    "# If there is no existing spark context, we now create a new context\n",
    "if (sc is None):\n",
    "    sc = SparkContext(master=\"local[4]\", appName=\"Assignment 2\")\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 02: Load the dataset and print the schema and total number of entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the csv file have a header (column names in the first row) then set header=true. This will use the first row in the csv file as the dataframe's column names. Setting header=false (default option) will result in a dataframe with default column names: _c0, _c1, _c2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"weatherAUS.csv\", inferSchema=True, header=True).toDF(\"Date\",\"Location\",\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"Evaporation\",\"Sunshine\",\"WindGustDir\",\"WindGustSpeed\",\"WindDir9am\",\"WindDir3pm\",\"WindSpeed9am\",\"WindSpeed3pm\",\"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"Cloud9am\",\"Cloud3pm\",\"Temp9am\",\"Temp3pm\",\"RainToday\",\"RainTomorrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of entries in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142193"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- MinTemp: string (nullable = true)\n",
      " |-- MaxTemp: string (nullable = true)\n",
      " |-- Rainfall: string (nullable = true)\n",
      " |-- Evaporation: string (nullable = true)\n",
      " |-- Sunshine: string (nullable = true)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: string (nullable = true)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: string (nullable = true)\n",
      " |-- WindSpeed3pm: string (nullable = true)\n",
      " |-- Humidity9am: string (nullable = true)\n",
      " |-- Humidity3pm: string (nullable = true)\n",
      " |-- Pressure9am: string (nullable = true)\n",
      " |-- Pressure3pm: string (nullable = true)\n",
      " |-- Cloud9am: string (nullable = true)\n",
      " |-- Cloud3pm: string (nullable = true)\n",
      " |-- Temp9am: string (nullable = true)\n",
      " |-- Temp3pm: string (nullable = true)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Data Cleaning and Processing\n",
    "## Step 03: Delete columns from the dataset\n",
    "### * is used for unpacking the list. Here we have unpacked our list data and passed it to the drop function. Here every elements of the list dropped_columns will be unpacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = ['Date','Location','Evaporation','Sunshine','Cloud9am','Cloud3pm','Temp9am','Temp3pm']\n",
    "df = df.drop(*dropped_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MinTemp: string (nullable = true)\n",
      " |-- MaxTemp: string (nullable = true)\n",
      " |-- Rainfall: string (nullable = true)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: string (nullable = true)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: string (nullable = true)\n",
      " |-- WindSpeed3pm: string (nullable = true)\n",
      " |-- Humidity9am: string (nullable = true)\n",
      " |-- Humidity3pm: string (nullable = true)\n",
      " |-- Pressure9am: string (nullable = true)\n",
      " |-- Pressure3pm: string (nullable = true)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For testing purpose\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 04: Print the number of missing data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countNAData(column):\n",
    "    return df.filter(df[column]=='NA').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get the list of names from the schema we can use schema.names which actually returns the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = df.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp    637\n",
      "MaxTemp    322\n",
      "Rainfall    1406\n",
      "WindGustDir    9330\n",
      "WindGustSpeed    9270\n",
      "WindDir9am    10013\n",
      "WindDir3pm    3778\n",
      "WindSpeed9am    1348\n",
      "WindSpeed3pm    2630\n",
      "Humidity9am    1774\n",
      "Humidity3pm    3610\n",
      "Pressure9am    14014\n",
      "Pressure3pm    13981\n",
      "RainToday    1406\n",
      "RainTomorrow    0\n"
     ]
    }
   ],
   "source": [
    "for col in sf:\n",
    "    print(col ,'  ', countNAData(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 05: Fill the missing data with average value and maximum occurrence value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_column = ['MinTemp','MaxTemp','Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm']\n",
    "nonnumeric_columns = ['WindGustDir','WindDir9am','WindDir3pm','RainToday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mylist contains the mean for all the numeric column in numeric_column list. df.describe(['MinTemp']).collect() will provide the count, mean, stddev, min and max for 'MinTemp' column. As well as, nonnumericlist contains maximum frequency value.\n",
    "#### df.describe(['MinTemp']).collect()[0]['MinTemp'] -> count\n",
    "#### df.describe(['MinTemp']).collect()[1]['MinTemp'] -> mean\n",
    "#### df.describe(['MinTemp']).collect()[4]['WindGustDir'] -> maximum frequency of a word in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = []\n",
    "for i in numeric_column:\n",
    "    mylist.append(df.describe([i]).collect()[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonnumericlist = []\n",
    "for i in nonnumeric_columns:\n",
    "    nonnumericlist.append(df.describe([i]).collect()[4][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating udf function for each column in order to assign the average value for the numeric column and maximum frequency value for non numeric column where 'NA' was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgColMinTemp = udf(lambda x: mylist[0] if x=='NA' else x)\n",
    "avgColMaxTemp = udf(lambda x: mylist[1] if x=='NA' else x)\n",
    "avgColRainfall = udf(lambda x: mylist[2] if x=='NA' else x)\n",
    "avgColWindGustSpeed = udf(lambda x: mylist[3] if x=='NA' else x)\n",
    "avgColWindSpeed9am= udf(lambda x: mylist[4] if x=='NA' else x)\n",
    "avgColWindSpeed3pm= udf(lambda x: mylist[5] if x=='NA' else x)\n",
    "avgColHumidity9am= udf(lambda x: mylist[6] if x=='NA' else x)\n",
    "avgColHumidity3pm= udf(lambda x: mylist[7] if x=='NA' else x)\n",
    "avgColPressure9am= udf(lambda x: mylist[8] if x=='NA' else x)\n",
    "avgColPressure3pm= udf(lambda x: mylist[9] if x=='NA' else x)\n",
    "freqWindGustDir = udf(lambda x: nonnumericlist[0] if x=='NA' else x)\n",
    "freqWindDir9am = udf(lambda x: nonnumericlist[1] if x=='NA' else x)\n",
    "freqWindDir3pm = udf(lambda x: nonnumericlist[2] if x=='NA' else x)\n",
    "freqRainToday = udf(lambda x: nonnumericlist[3] if x=='NA' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('MinTemp',avgColMinTemp(df['MinTemp']))\\\n",
    ".withColumn('MaxTemp',avgColMaxTemp(df['MaxTemp']))\\\n",
    ".withColumn('Rainfall',avgColRainfall(df['Rainfall']))\\\n",
    ".withColumn('WindGustSpeed',avgColWindGustSpeed(df['WindGustSpeed']))\\\n",
    ".withColumn('WindSpeed9am',avgColWindSpeed9am(df['WindSpeed9am']))\\\n",
    ".withColumn('WindSpeed3pm',avgColWindSpeed3pm(df['WindSpeed3pm']))\\\n",
    ".withColumn('Humidity9am',avgColHumidity9am(df['Humidity9am']))\\\n",
    ".withColumn('Humidity3pm',avgColHumidity3pm(df['Humidity3pm']))\\\n",
    ".withColumn('Pressure9am',avgColPressure9am(df['Pressure9am']))\\\n",
    ".withColumn('Pressure3pm',avgColPressure3pm(df['Pressure3pm']))\\\n",
    ".withColumn('WindGustDir',freqWindGustDir(df['WindGustDir']))\\\n",
    ".withColumn('WindDir9am',freqWindDir9am(df['WindDir9am']))\\\n",
    ".withColumn('WindDir3pm',freqWindDir3pm(df['WindDir3pm']))\\\n",
    ".withColumn('RainToday',freqRainToday(df['RainToday']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 06: Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type casting has been done- Double for the numeric value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "df =  df.withColumn(\"MinTemp\",df[\"MinTemp\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"MaxTemp\",df[\"MaxTemp\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"Rainfall\",df[\"Rainfall\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"WindGustSpeed\",df[\"WindGustSpeed\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"WindSpeed9am\",df[\"WindSpeed9am\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"WindSpeed3pm\",df[\"WindSpeed3pm\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"Humidity9am\",df[\"Humidity9am\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"Humidity3pm\",df[\"Humidity3pm\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"Pressure9am\",df[\"Pressure9am\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"Pressure3pm\",df[\"Pressure3pm\"].cast(types.DoubleType()))\\\n",
    "        .withColumn(\"WindGustDir\",df[\"WindGustDir\"])\\\n",
    "        .withColumn(\"WindDir9am\",df[\"WindDir9am\"])\\\n",
    "        .withColumn(\"WindDir3pm\",df[\"WindDir3pm\"])\\\n",
    "        .withColumn(\"RainToday\",df[\"RainToday\"])\\\n",
    "        .withColumn(\"RainTomorrow\",df[\"RainTomorrow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "WindGustDir_indexer = StringIndexer(inputCol=\"WindGustDir\", outputCol=\"WindGustDir_index\")\n",
    "WindDir9am_indexer = StringIndexer(inputCol=\"WindDir9am\", outputCol=\"WindDir9am_index\")\n",
    "WindDir3pm_indexer = StringIndexer(inputCol=\"WindDir3pm\", outputCol=\"WindDir3pm_index\")\n",
    "RainToday_indexer = StringIndexer(inputCol=\"RainToday\", outputCol=\"RainToday_index\")\n",
    "RainTomorrow_indexer = StringIndexer(inputCol=\"RainTomorrow\", outputCol=\"RainTomorrow_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = WindGustDir_indexer.fit(df).transform(df)\n",
    "df = WindDir9am_indexer.fit(df).transform(df)\n",
    "df = WindDir3pm_indexer.fit(df).transform(df)\n",
    "df = RainToday_indexer.fit(df).transform(df)\n",
    "df = RainTomorrow_indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since it is told in the marking rubric to drop the orginal columns whose indexing is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 07: Create the feature vector and divide the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorAssembler is a transformer that combines a given list of columns into a single vector column \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler = VectorAssembler(inputCols=[\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"WindGustDir_index\",\"WindDir9am_index\",\"WindDir3pm_index\",\"RainToday_index\"],outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vector_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I hope will not make any effect after deleting this\n",
    "#columns since they are not used in the following stages\n",
    "#df = df.drop(\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"WindGustDir_index\",\"WindDir9am_index\",\"WindDir3pm_index\",\"RainToday_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Splitting the dataset between training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed = 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Apply Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol=\"RainTomorrow_index\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = decision_tree.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|prediction|RainTomorrow_index|\n",
      "+----------+------------------+\n",
      "|       0.0|               0.0|\n",
      "|       0.0|               0.0|\n",
      "|       1.0|               1.0|\n",
      "|       1.0|               1.0|\n",
      "|       1.0|               0.0|\n",
      "|       0.0|               0.0|\n",
      "+----------+------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_predictions.select('prediction','RainTomorrow_index').show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Accuracy 0.8346073176415754\n",
      "Test Error = 0.165393 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "dt_evaluator = MulticlassClassificationEvaluator(\\\n",
    "\n",
    "labelCol=\"RainTomorrow_index\", predictionCol=\"prediction\",\\\n",
    "\n",
    "metricName=\"accuracy\")\n",
    "\n",
    "dt_accuracy = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"DecisionTreeClassifier Accuracy\",dt_accuracy)\n",
    "print(\"Test Error = %g \" % (1.0 - dt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and calculate the accuracy of random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"RainTomorrow_index\",\\\n",
    "featuresCol=\"features\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|prediction|RainTomorrow_index|\n",
      "+----------+------------------+\n",
      "|       0.0|               0.0|\n",
      "|       0.0|               0.0|\n",
      "|       1.0|               1.0|\n",
      "|       1.0|               1.0|\n",
      "|       1.0|               0.0|\n",
      "+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions.select(\"prediction\", \"RainTomorrow_index\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_index\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Accuracy:  0.8360755068748543\n",
      "Test Error = 0.163924\n"
     ]
    }
   ],
   "source": [
    "rf_accuracy = rf_evaluator.evaluate(rf_predictions)\n",
    "print (\"RandomForestClassifier Accuracy: \",rf_accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - rf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and calculate the accuracy of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'RainTomorrow_index',    maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|prediction|RainTomorrow_index|\n",
      "+----------+------------------+\n",
      "|       0.0|               0.0|\n",
      "|       0.0|               0.0|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predictions.select(\"prediction\", \"RainTomorrow_index\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_evaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_index\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  0.8176182707993475\n",
      "Test Error = 0.182382\n"
     ]
    }
   ],
   "source": [
    "lr_accuracy = lr_evaluator.evaluate(lr_predictions)\n",
    "print (\"Logistic Regression Accuracy: \",lr_accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - lr_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and calculate the accuracy of Gradient-Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if maxIter=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(featuresCol = 'features', labelCol = 'RainTomorrow_index', maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model = gbt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_predictions = gbt_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|prediction|RainTomorrow_index|\n",
      "+----------+------------------+\n",
      "|       0.0|               0.0|\n",
      "|       0.0|               0.0|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_predictions.select(\"prediction\", \"RainTomorrow_index\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "gbt_evaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_index\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_accuracy = gbt_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-Boosted Tree Classifier Accuracy:  0.8419482638079702\n",
      "Test Error = 0.158052\n"
     ]
    }
   ],
   "source": [
    "print (\"Gradient-Boosted Tree Classifier Accuracy: \",gbt_accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - gbt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar chart to demonstrate the comparison of their accuracy.\n",
    "#### DT ->  DecisionTreeClassifier\n",
    "#### RF ->  RandomForestClassifier\n",
    "#### LR ->  LogisticRegression\n",
    "#### GBT -> GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = [dt_accuracy,rf_accuracy,lr_accuracy,gbt_accuracy]\n",
    "accuracy_name = [\"DT\",\"RF\",\"LR\",\"GBT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5gdVZ3u8e+bBEzCRaNpRcIlUUBFFNQGGbyMCopXggoKDgM6g4AjolFRmeMxiA/KjHgFHYzIRbkdjOjEUSGAg4Ig0IGIBETugYDYGiRcIgR4zx+1GjZN9+5K07t7d+/38zz1pGpVrapfbWN+rKpVa8k2ERER7WbSWAcQERExkCSoiIhoS0lQERHRlpKgIiKiLSVBRUREW0qCioiItpQEFREjRtK/Szp+rOOIiUH5DirGE0kXANsCG9l+cIzDaQlJAj4CHADMAe4GLgGOsP37sYwtYjSlBRXjhqTZwGsAA7uN8rWnjOLlvgF8FDgEeCawFfAT4G2jGMNaG+XfKDpAElSMJ/sCvwVOAvZr3CFpmqSvSLpV0j2SLpI0rex7taSLJf1N0m2S3l/KL5C0f8M53i/pooZtS/qwpOuB60vZN8o5VklaIuk1DcdPLo+4bpR0b9m/qaRvSfpKv3gXSZrX/wYlbQl8GNjb9i9tP2j7Adun2j6qHPN0Sd+X1Fvu97OSJjXcw28kfa3c702Sdirlt0n6s6T9Gq53kqTjJJ1bYv6VpM0b9je738MlLZR0iqRVwPtL2Sll/9Sy768llsslPafs27j8Bisl3SDpg/3Oe2a5x3slLZPUPcTfjZiAkqBiPNkXOLUsu/b9Y1ccDbwC2Imq1fEp4NHyj+0vgGOALmA7YOlaXHN34JXA1mX78nKOZwKnAT+UNLXs+ziwN/BWYEPgX4AHgJOBvRuSyExgl1K/v52B221f1iSmY4CnA88D/pHqd/lAw/5XAlcBzyrXOAPYHtgC2Ac4VtL6Dcf/E/AFYCbVb3Nqw75m9wswF1gIPKNfPaj+I+LpwKYlloOA1WXfGcDtwMbAHsAXJb2hoe5u5ZhnAIuAY5v8HjFR2c6Spe0X4NXAGmBm2f4DMK+sT6L6h2/bAeodBvx4kHNeAOzfsP1+4KKGbQNvGCKuu/uuC1wHzB3kuGuBN5b1g4GfD3Lc/wF+2+R6k4GHgK0byg4ELmi4h+sb9r2k3MdzGsr+CmxX1k8CzmjYtz7wCLBpjfs9HPh1v/2HA6eU9X8BLgZe2u+YTcs1Nmgo+xJwUsM5zmvYtzWweqz/DmYZ/SUtqBgv9gMW2/5L2T6Nxx/zzQSmAjcOUG/TQcrruq1xQ9InJV1bHiP+jaqFMLPGtU6mar1Q/vzBIMf9FXhuk3hmAusAtzaU3QrMati+q2F9NYDt/mWNLajH7tH2fcBKqpbNUPf7hLoD+AFwDnCGpDsk/aekdcq5V9q+t8k9/Klh/QFgat5xdZ4kqGh75V3Se4B/lPQnSX8C5gHbStoW+Avwd+D5A1S/bZBygPuB6Q3bGw1wzGPdXMv7l0+VWGbYfgZwD6Aa1zoFmFvifRFVp4eBnA9s0uSdy1+oWpKbN5RtBqwY5Pg6Nu1bKY/+ngncUeN+oeH36c/2Gtuft7011aPXt1M9jrwDeKakDUbwHmICSoKK8WB3qkdCW1O9D9mO6h/5C4F9bT8KnAB8tbx8nyzpHyQ9jeq9yC6S3iNpiqRnSdqunHcp8C5J0yVtAfzrEHFsADwM9AJTJH2O6l1Tn+OBL0jaUpWXSnoWgO3bqd7n/AD4ke3VDMD29cC3gdMlvU7SuqWzwV6SPmP7EeBM4EhJG5R3bB+nSoDD9VZVHUnWpXoX9Vvbt9W436YkvV7SSyRNBlZRJdZHy7kvBr5U7u2lVL/9U7mHmICSoGI82A840fZy23/qW6henP9TefTzSeD3VElgJfAfwCTby6k6LXyilC+l+o4K4GtU73PuonoE1/8lf3/nAGcDf6R6JPV3nviI66tUyWMx1T/I3wOmNew/meqd0GCP9/ocUu7tW8DfqB4bvhP4adn/EarW303ARVSPO08Y4pzNnAbMp/p9XsHjjyKHut+hbETVgWIV1Tu4X/H4ve8NzKZqTf0YmG/7vKdwDzEB5UPdiFEi6bVUrYTN3Sb/x5N0ElWvwc+OdSwR/aUFFTEKSueAjwLHt0tyimh3SVARLSbpRVSP6p4LfH2Mw4kYN/KILyIi2lJaUBER0ZYmzIdvM2fO9OzZs8c6jIiIWEtLliz5i+2u/uUTJkHNnj2bnp6esQ4jIiLWkqRbByrPI76IiGhLSVAREdGWkqAiIqItJUFFRERbSoKKiIi21NIEJWlema75akmnl5GLT5J0s6SlZdlukLr7Sbq+LPsNdExERExcLetmLmkW1ajMW9teLelMYK+y+1DbC5vUfSbV6MrdVPPNLJG0yPbdrYo3IiLaS6sf8U0BppXpEKZTDa1fx67AubZXlqR0LvDmFsUYERFtqGUJyvYK4GhgOXAncI/txWX3kZKukvS1Mqlcf7N44rwzt/PE6aABkHSApB5JPb29vSN8BxERMZZalqAkzQDmAnOAjYH1JO0DHAa8ENieamrpTw/3GrYX2O623d3V9aRRMiIiYhxr5SO+XYCbbffaXgOcBexk+05XHgROBHYYoO4KYNOG7U1KWUREdIhWJqjlwI6SpksSsDNwraTnApSy3YGrB6h7DvAmSTNKS+xNpSwiIjpEy3rx2b5U0kLgCuBh4EpgAfALSV2AgKXAQQCSuoGDbO9ve6WkLwCXl9MdYXtlq2KNiIj2M2EmLOzu7nZGM4+IGH8kLbHd3b88I0lERERbSoKKiIi2lAQVERFtadBOEpJWDVFXwJ22txrZkCIiIpr34rvR9suaVZZ05QjHExERATR/xPfuGvXrHBMREbHWBk1Qtm/qXyZpZ0nvkLTOYMdERESMhNqdJCR9BXgVsC3w3y2LKCIiguadJL4CfMH230rRZsB7yvrvWx1YRER0tmYtqLOAMyQdImky8H3gf4FLgO+ORnAREdG5mr2D+o3tNwMrqQZqle3X2d7R9jdGLcKIiOhIgyYoSVMkvQ34M9Wo49tKWiRp21GLLiIiOlaz76B+QvU4bzrwT7b3k7QxcIQk2/7gqEQYEREdqVmC2tz22yWtC/wWwPYdwP6SthuV6CIiomM1S1DfkXRJWf9q4w7bS1sXUkRERJMEZftY4NhRjCUiIuIxQ3WSOFDSLyRdVZZfSDqobySJoUiaJ2mZpKslnS5pasO+b0q6b5B6syWtlrS0LMet/a1FRMR41uwR3w+AvwGfB24vZZsA+wGnAO9tdmJJs4BDgK1tr5Z0JrAXcFKZ3n3GELHdaDvvuiIiOlSzBPWKAabSuB34raQ/rsX5p0laQ9Ub8I7y0e+XgfcB71zbgCMiojM0G0lipaQ9JT12jKRJkt4L3D3UiW2vAI4GlgN3AvfYXgwcDCyyfecQp5gj6UpJv5L0moEOkHSApB5JPb29vUOFFBER40izBLUXsAdwl6Q/SroeuAt4V9nXlKQZwFxgDrAxsJ6kfYE9gWOGqH4nsFmZj+rjwGmSNux/kO0Ftrttd3d1dQ0VUkREjCPNevHdQnnPJOlZpeyva3HuXYCbbfeWc5xF9T5rGnCDJIDpkm6wvUW/az8IPFjWl0i6EdgK6FmL60dExDjW7B0Ukl5I1QqaVbZXAP9t+w81zr0c2FHSdGA1sDPwVduPtZ4k3dc/OZXyLmCl7UckPQ/YEsjcUxERHaRZN/NPA2cAAi4ri6hGOP/MUCe2fSmwELiCanqOScCCJtfbTdIRZfO1wFWSlpZzHGR7Za07ioiICUG2B95R9dR7se01/crXBZbZ3nIU4qutu7vbPT15AhgRMd5IWmK7u395s04Sj1J1bujvuWVfREREyzR7B/Ux4PzSe++2UrYZsAVVV/GIiIiWadaL72xJWwE7UDpJACuAy20/MhrBRURE52rai8/2o5SpNhpJWt/2gOPoRUREjIRm76CauWZEo4iIiOhn0BaUpI8PtgtYvzXhREREVJq1oL5INeL4Bv2W9YeoFxER8ZQ1ewd1BfAT20v675C0f+tCioiIaJ6gPgAMNvbekz6oioiIGEnNuplf12TfXa0JJyKis8z+zM/GOoSn5Jaj3tayc+ddUkREtKUkqIiIaEvNRjP/j/LnnqMXTkRERKVZC+qtqmYVPGy0gomIiOjTrBff2cDdwPqSVlF9oOu+P20/aQr2iIiIkTJoC8r2obafAfzM9oa2N2j8s87JJc2TtEzS1ZJOlzS1Yd83JQ06np+kwyTdIOk6Sbuu1V1FRMS4N2QnCdtzJT1H0tvL0lXnxJJmAYcA3ba3ASYDe5V93VSjVAxWd+ty7IuBNwPfljS5znUjImJiGDJBlU4SlwF7Au8BLpO0R83zTwGmSZoCTAfuKInmy8CnmtSbC5xh+0HbNwM3UE37ERERHaLpdBvFZ4Htbf8ZoLSgzgMWNqtke4Wko4HlwGpgse3Fkj4KLLJ9Z9UHY0CzeOI0H7fz+JxUERHRAep8BzWpLzkVf61TT9IMqpbQHKqp49eTtC9VS+yYYcQ60DUOkNQjqae3t3ckThkREW2iTgvqbEnnAKeX7fcCP69RbxfgZtu9AJLOAj4PTANuKK2n6ZJusL1Fv7orgE0btjcpZU9gewGwAKC7u9s1YoqIiHGiTieJQ4HvAC8tywLbn65x7uXAjpKml++pdga+ansj27NtzwYeGCA5ASwC9pL0NElzgC2p3oNFRESHqNOCwvZZwFlrc2Lbl0paSDVtx8PAlZTWzkAk7UbV4+9ztpdJOpNq5t6HgQ/bfmRtrh8REeNbrQQ1XLbnA/Ob7F+/YX0RVcupb/tI4MhWxhcREe0rg8VGRERbqtMb76N1yiIiIkZSnRbUfgOUvX+E44iIiHiCQd9BSdobeB8wR9Kihl0bACtbHVhERHS2Zp0kLgbuBGYCX2kovxe4qpVBRUREDJqgbN8K3Ar8w+iFExERURmym7mke6nmgQJYF1gHuD/zQUVERCsNmaBsb9C3XkaEmAvs2MqgIiIi1uo7KFd+AmQCwYiIaKk6j/je1bA5CegG/t6yiCIiIqg31NE7GtYfBm6heswXERHRMnXeQX1gNAKJiIho1PQdlKS3SPq1pL+U5VeS3jpawUVEROdqNpLEB4EDgU8BPaW4GzhK0iZlssCIiIiWaPaIbx7watuNwxr9UtJbgItoMrdTxHDM/szPxjqEYbvlqLeNdQgRE06zR3zql5wAsP3XFsYTEREBNE9QqyRt27+wlN1b5+SS5klaJulqSadLmirpe5J+J+kqSQslrT9AvdmSVktaWpbj6t9SRERMBM0e8X0CWCTpRGBJKeummn5jn6FOLGkWcAiwte3VZQr3vYB5tleVY74KHAwcNcApbrS9Xe07iYiICWXQFpTti4AdyjHvL8skYMeyr44pwDRJU4DpwB0NyUnANB4f5y8iIuIxTb+Dsn0X8LnhnNj2CklHA8uB1cBi24sBSqvsrcA1VC21gcyRdCWwCvis7Qv7HyDpAOAAgM0222w4YUZERJsatAUlachees2OkTSDasSJOcDGwHqS9oHHPv7dGLgWeO8A1e8ENrP9MuDjwGmSnjR6uu0Ftrttd3d1dQ0VbkREjCPNWlC7S2o25p6A1zfZvwtws+1eAElnATsBpwDYfkTSGVTfWZ3YWNH2g8CDZX2JpBuBrXj8e6yWGM/dnCFdnSNiYmmWoA6tUf9Jj90aLAd2lDSd6hHfzkCPpC1s31DeQe0G/KF/RUldwMqSxJ4HbAncVCOeiIiYIJrNqHsygKR3AD+z/ejanNj2pZIWAldQDTJ7JdXHvb8sj+sE/A74ULnObkC37c8BrwWOkLQGeBQ4aKBvsiIiYuKqM5r5e4GvS/oRcILtJ7V4BmN7PjC/X/GrBjl2EbCorP8I+FHd60RExMQz5ISFtvcBXgbcCJwk6RJJB0jaYIiqERERw1ZrRt3y7dJC4AzgucA7gSskfaSFsUVERAcbMkFJ2k3Sj4ELgHWAHWy/BdiWwb9hioiIeErqvIN6N/A1279uLLT9gKR/bU1YERHR6eokqMOpPpwFQNI04Dm2b7F9fqsCi4iIzlbnHdQPqbp693mklEVERLRMnQQ1xfZDfRtlfd3WhRQREVEvQfWWj2gBkDQX+EvrQoqIiKj3Duog4FRJx1KN/nAbsG9Lo4qIiI43ZIKyfSPVmHrrl+37Wh5VRER0vDotKCS9DXgxMLUa4xVsH9HCuCIiosPV+VD3OKrx+D5C9YhvT2DzFscVEREdrk4niZ1s7wvcbfvzwD9Qzc0UERHRMnUSVN+khQ9I2hhYQzUeX0RERMvUeQf1U0nPAL5MNbeTge+2NKqIiOh4TROUpEnA+bb/BvxI0v8AU23fMyrRRUREx2r6iK/Movuthu0H1yY5SZonaZmkqyWdLmmqpO9J+p2kqyQt7Ou+PkDdwyTdIOk6SbvWvqOIiJgQ6ryDOl/Su9XXv7wmSbOAQ6imcd8GmAzsBcyzva3tlwLLgYMHqLt1OfbFwJuBb0uavDbXj4iI8a1OgjqQanDYByWtknSvpFU1zz8FmCZpCjAduKNMfkhJeNOo3mn1Nxc4o7TYbgZuAHaoec2IiJgA6kz5voHtSbbXtb1h2d6wRr0VwNFUraQ7gXtsLwaQdCLwJ+CFwDEDVJ9FNaRSn9tL2ROUqed7JPX09vYOFVJERIwjdT7Ufe1AS416M6haQnOAjYH1JO0DYPsDpexaqo+Ah8X2Atvdtru7urqGe5qIiGhDdbqZH9qwPpXqUdsS4A1D1NsFuNl2L4Cks4CdgFMAbD8i6QzgU8CJ/equADZt2N6klEVERIeo84jvHQ3LG4FtgLtrnHs51SCz08v7pp2BayVtAY+9g9oN+MMAdRcBe0l6mqQ5wJbAZfVuKSIiJoJag8X2czvwoqEOsn2ppIVUH/c+DFwJLAB+KWlDqnH9fgd8CKDMOdVt+3O2l0k6E7im1P2w7UeGEWtERIxTQyYoScfweE+7ScB2VElnSLbnA/P7Fb9qkGMXUbWc+raPBI6sc52IiJh46rSgehrWHwZOt/2bFsUTEREB1EtQC4G/9z1ikzRZ0nTbD7Q2tIiI6GS1RpKg+qC2zzTgvNaEExERUamToKY2TvNe1qe3LqSIiIh6Cep+SS/v25D0CmB160KKiIio9w7qY8APJd1B1TV8I57C6A8RERF1DJmgbF8u6YXAC0rRdbbXtDasiIjodHXG4vswsJ7tq21fDawv6d9aH1pERHSyOu+gPlhm1AXA9t3AB1sXUkRERL0ENblxssIyceC6rQspIiKiXieJs4H/J+k7ZfvAUhYREdEydRLUp6mS0ofK9rnA8S2LKCIignq9+B4F/qssERERo6LOaOZbAl8CtqaasBAA289rYVwREdHh6nSSOJGq9fQw8Hrg+5RZcSMiIlqlToKaZvt8QLZvtX048LbWhhUREZ2uTieJByVNAq6XdDCwAli/zsklzQP2p5rw8PfAB4DvAd3AGqpp3A8caGQKSY+UOgDLbe9W55oRETEx1GlBfZRq9PJDgFcA+wD7DVVJ0qxSp9v2NsBkYC/gVOCFwEuopu7Yf5BTrLa9XVmSnCIiOkytsfjK6n1ULaC1Pf80SWuoktwdthf37ZR0GbDJWp4zIiI6QJ0W1LDYXgEcDSwH7gTu6Zec1gH+mcE/+p0qqUfSbyXtPtABkg4ox/T09vaO8B1ERMRYalmCkjQDmAvMATYG1pO0T8Mh3wZ+bfvCQU6xue1u4H3A1yU9v/8BthfY7rbd3dXVNcJ3EBERY2nQBCXpP8qfew7z3LsAN9vuLZ0gzgJ2KuecD3QBHx+scmmBYfsm4ALgZcOMIyIixqFmLai3lkFiDxvmuZcDO0qaXs6zM3CtpP2BXYG9yygVTyJphqSnlfWZwKuAa4YZR0REjEPNOkmcDdxNNf/TKqrZdN33p+0Nm53Y9qWSFgJXUH3keyWwALgfuBW4pAySfpbtIyR1AwfZ3h94EfAdSY9SJdGjbCdBRUR0kEETlO1DgUMl/bftucM5ue35wPw617TdQ+lybvtiqm7oERHRoep0M58r6TnA9qXoUtvpMhcRES1VZ8r3PalGfNgTeA9wmaQ9Wh1YRER0tjpDHX0W2N72nwEkdQHnAQtbGVhERHS2Ot9BTepLTsVfa9aLiIgYtlpTvks6Bzi9bL8X+HnrQoqIiKjXSeJQSe8CXl2KFtj+cWvDioiITlenBYXts6hGgoiIiBgVeZcUERFtKQkqIiLaUq0EJWmapBe0OpiIiIg+dT7UfQewlDJvk6TtJC1qdWAREdHZ6rSgDgd2AP4GYHsp1RxPERERLVMnQa2xfU+/MrcimIiIiD51upkvk/Q+YLKkLYFDgItbG1ZERHS6Oi2ojwAvBh6kGk1iFfCxVgYVERExZIKy/YDt/2N7e9vdZf3vdU4uaZ6kZZKulnS6pKmSTpV0XSk7QdI6g9TdT9L1ZdlvbW8sIiLGtyEf8Un6KU9+53QP0AN8Z7BkJWkW1ePArW2vlnQmsBdwKrBPOew0qkkK/6tf3WdSTXTYXa69RNIi23fXvbGIiBjf6jziuwm4D/huWVYB9wJble1mpgDTJE0BpgN32P65C6p5pjYZoN6uwLm2V5akdC7w5jo3FBERE0OdThI72d6+Yfunki63vb2kZYNVsr1C0tHAcmA1sNj24r795dHePwMfHaD6LOC2hu3bS1lERHSIOi2o9SVt1rdR1tcvmw8NVknSDGAu1TdTGwPrSdqn4ZBvA7+2feFaR/34NQ6Q1COpp7c3s9BHREwkdRLUJ4CLJP2vpAuAC4FPSloPOLlJvV2Am2332l5DNRr6TgCS5gNdwMcHqbsC2LRhe5NS9gS2F5SOG91dXV01biUiIsaLOvNB/bx8//TCUnRdQ8eIrzepuhzYUdJ0qkd8OwM9kvanese0s+1HB6l7DvDF0goDeBNw2FCxRkTExFFrPihgS+AFwFRgW0nY/n6zCrYvlbQQuAJ4GLgSWADcD9wKXCIJ4CzbR0jqBg6yvb/tlZK+AFxeTneE7ZVre3MRETF+1elmPh94HbA11VTvbwEuApomKADb86m6iw95Tds9VF3O+7ZPAE4Y6hoRETEx1XkHtQfV47k/2f4AsC3w9JZGFRERHa9Oglpd3hU9LGlD4M88sQNDRETEiKvzDqpH0jOoPspdQvXR7iUtjSoiIjpenV58/1ZWj5N0NrCh7ataG1ZERHS6OjPqnt+3bvsW21c1lkVERLTCoC0oSVOpxs+bWb5HUtm1IRl2KCIiWqzZI74DqeZ92pjq3VNfgloFHNviuCJiFM3+zM/GOoSn5Jaj3jbWIUQLDJqgbH8D+Iakj9g+ZhRjioiIqNVJ4hhJOwGzG48faiSJiIiIp6LOSBI/AJ4PLAUeKcWmxkgSERERw1XnO6huqllx+8+qGxER0TJ1RpK4Gtio1YFEREQ0qtOCmglcI+ky4MG+Qtu7tSyqiIjoeHUS1OGtDiIiIqK/Or34fiVpc2BL2+eVCQgntz60iIjoZHWGOvogsBD4TimaBfyklUFFRETU6STxYeBVVCNIYPt64Nl1Ti5pnqRlkq6WdLqkqZIOlnSDJEua2aTuI5KWlmVRnetFRMTEUecd1IO2HyrTsyNpCtV3UE1JmgUcQtVFfbWkM4G9gN8A/wNcMMQpVtverkZ8ERExAdVJUL+S9O/ANElvBP4N+OlanH+apDVUA8/eYftKgL6EFxERMZA6j/g+A/QCv6caQPbnwGeHqmR7BXA0sBy4E7jH9uK1iG2qpB5Jv5W0+0AHSDqgHNPT29u7FqeOiIh2VydBTQNOsL2n7T2AE0pZU2WKjrnAHKoR0deTtM9axLa57W7gfcDXJT2//wG2F9jutt3d1dW1FqeOiIh2VydBnc8TE9I04Lwa9XYBbrbda3sNcBawU93ASgsM2zdRva96Wd26EREx/tVJUFNt39e3Udan16i3HNhR0nRVL5x2Bq6tE5SkGZKeVtZnUvUivKZO3YiImBjqJKj7Jb28b0PSK4DVQ1WyfSnV91NXUL2/mgQskHSIpNuBTYCrJB1fztvdtw68COiR9Dvgf4GjbCdBRUR0kDq9+D4K/FDSHVSz6m4EvLfOyW3PB+b3K/5mWfof2wPsX9YvBl5S5xoRETExNU1QkiYB6wIvBF5Qiq8r75QiIiJapmmCsv2opG/ZfhnVtBsRERGjolYvPknvVr6sjYiIUVQnQR0I/BB4SNIqSfdKWtXiuCIiosPVmW5jg9EIJCIiolGd6TYkaR9J/7dsbypph9aHFhERnazOI75vA/9ANeQQwH3At1oWUUREBPW+g3ql7ZdLuhLA9t2S1m1xXBER0eHqtKDWSJpMmQNKUhfwaEujioiIjlcnQX0T+DHwbElHAhcBX2xpVBER0fHq9OI7VdISqsFeBexuu9agrxEREcM1aIKSNBU4CNiCarDX79h+eLQCi4iIztbsEd/JQDdVcnoL1ey4ERERo6LZI76tbb8EQNL3gMtGJ6SIiIjmLajHRizPo72IiBhtzVpQ2zaMuSdgWtkWYNsbtjy6iIjoWIO2oGxPtr1hWTawPaVhvVZykjRP0jJJV0s6XdJUSQdLukGSy3Tug9XdT9L1ZdlvODcXERHjV53voIZF0izgEKDb9jbAZGAv4DfALsCtTeo+k2om3lcCOwDzJc1oVawREdF+WpagiilUjwanANOBO2xfafuWIertCpxre6Xtu4FzgTe3NtSIiGgnLUtQtldQdU1fDtwJ3GN7cc3qs4DbGrZvL2VPIOkAST2Senp7e59qyBER0UZa+YhvBjAXmANsDKwnaZ+RvIbtBba7bXd3dXWN5KkjImKMtfIR3y7AzbZ7ba8BzgJ2qll3BbBpw/YmpSwiIjpEKxPUcmBHSdMliWosv7pj+J0DvEnSjNISe1Mpi4iIDtHKd1CXAguBK6iGS5oELJB0iKTbqVpFV0k6HkBSd9+67ZXAF4DLy3JEKYuIiA5RZ8LCYbM9n6q7eKNvlqX/sT3A/g3bJwAntDK+iIhoX63uZh4RETEsSVAREdGWkoGj3KYAAAVTSURBVKAiIqItJUFFRERbSoKKiIi2lAQVERFtSbbHOoYRIamXJiOkt4mZwF/GOogOld9+bOX3Hzvj4bff3PaTxqubMAlqPJDUY7t7rOPoRPntx1Z+/7Eznn/7POKLiIi2lAQVERFtKQlqdC0Y6wA6WH77sZXff+yM298+76AiIqItpQUVERFtKQkqIiLaUhJUC0h6RNJSScsk/U7SJyRNkrRrKV8q6T5J15X17491zBNJw+9/taSfSnpGKZ8taXXD/wZLJa071vFONJLuG6DscEkrym9+jaS9xyK2iUbScySdJukmSUskXSLpnZJeJ+me8ntfJek8Sc+W9IGGv/sPSfp9WT9qrO9lIHkH1QKS7rO9fll/NnAa8JsyP1bfMRcAnyzzYMUI6vf7nwz80faRkmYD/2N7m7GMb6Jr/P0byg4H7rN9tKQtgSXAs2yvGYsYJ4IyU/nFwMm2jytlmwO7UU0S+0nbby/lXwIe6vdv0C1At+22/Yg3LagWs/1n4ADg4PIXKkbXJcCssQ4iHmf7euABYMZYxzLOvYEq6RzXV2D7VtvHNB5U/t3ZALh7lON7ypKgRoHtm4DJwLPHOpZOImkysDOwqKH4+Q2POL41RqF1NEkvB64v//EWw/di4Iom+18jaSmwHNiFcThDeRJUTETTyv8x/wQ8Bzi3Yd+Ntrcry4fHJryONU/SMuBS4MixDmaikfSt8s778lJ0Yfl7vilwIvCfYxjesCRBjQJJzwMeAfJfjKNjte3tgM0BAUlE7eFrtl8MvBv4nqSpYx3QOLcMeHnfRvkPrp2BJw26SvUU4bWjFNeISYJqMUldwHHAsU6PlFFl+wHgEOATkqaMdTxRsb0I6AH2G+tYxrlfAlMlfaihbPogx74auLH1IY2s/J+2NfoeMa0DPAz8APjq2IbUmWxfKekqYG/gwrGOp0NMl3R7w/ZAf/ePAE6T9F3bj45SXBOKbUvaHfiapE8BvcD9wKfLIX3voATcA+w/NpEOX7qZR0REW8ojvoiIaEtJUBER0ZaSoCIioi0lQUVERFtKgoqIiLaUBBUxwiRtJOkMSTeWEaZ/LmkrSVeP4DWOkLRLWX9NGTl/qaRZkhaO1HUixlK6mUeMoEFGmN4W2BD4r1aMpC7pOOAi26cMo+4U2w+PdEwRIyEtqIiR9XpgTb8Rpn8H3Na3XealulDSFWXZqZQ/V9KvG+ayeo2kyZJOKtu/lzSvHHuSpD0k7Q+8B/iCpFPLua8ux0yW9GVJl5c5gQ4s5a8r118EXDNqv0zEWspIEhEjaxuquY6a+TPwRtt/L3MjnQ50A+8DzilzV02mGrZmO2BWX8urb/LFPraPl/RqqnmuFpY5r/r8K3CP7e0lPQ34jaTFZd/LgW1s3/xUbjailZKgIkbfOsCxkrajGkR4q1J+OXCCpHWAn9heKukm4HmSjgF+Biwe8IwDexPwUkl7lO2nA1sCDwGXJTlFu8sjvoiRtQx4xRDHzAPuAralajmtC2D711QjTq8ATpK0r+27y3EXAAcBx69FLAI+0jC9yBzbfQnu/rU4T8SYSIKKGFm/BJ4m6YC+AkkvBTZtOObpwJ1lkNR/pprMsm+67rtsf5cqEb1c0kxgku0fAZ+lYXqFGs4BPlRaZJSehOsN/9YiRlce8UWMoDLC9DuBr0v6NPB34BbgYw2HfRv4kaR9gbN5vDXzOuBQSWuA+4B9qaarP1FS339MHrYW4RwPzAauKL0Le4Hdh3FbEWMi3cwjIqIt5RFfRES0pSSoiIhoS0lQERHRlpKgIiKiLSVBRUREW0qCioiItpQEFRERben/A5ub6T9+FV9zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects= (name for name in accuracy_name)\n",
    "# prepare data\n",
    "y_axis = [ac*100 for ac in accuracy_list]\n",
    "\n",
    "# plot\n",
    "bar_width = 0.5\n",
    "objects= accuracy_name\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "min_y = min(y_axis) - 1\n",
    "max_y = max(y_axis) + 1\n",
    "plt.bar(y_pos, y_axis, bar_width, align='center', color='C0')\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylim([min_y,max_y])\n",
    "plt.ylabel('Percentage of accuracy[Out of 100%]')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above bar graph illustrates the percentage of accuracy for each classifier. Overall the accuracy of GBT is better compared to other three classifier. From DT to RF, accuracy increases gradually but for LR it is suddenly dropped. Again for GBT it is jumped suddenly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 09: Calculate the confusion matrix and find the precision, recall, and F1 score of each classification algorithm. Explain how the accuracy of the predication can be improved?\n",
    "### I have considered the following thing:\n",
    "#### If rain occurs: 1.0 which is positive and if it doesn't rain then 0.0 which is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For DecisionTreeClassifier\n",
    "\n",
    "#### tp_dt -> Store True Positive\n",
    "#### tn_dt -> Store True Negative\n",
    "#### fp_dt -> Store False Positive\n",
    "#### fn_dt -> Store False Negative\n",
    "#### precision_dt -> Precision \n",
    "#### recall_dt -> Recall\n",
    "#### f1score_dt -> F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_dt = dt_predictions[(dt_predictions.RainTomorrow_index == 1.0) & (dt_predictions.prediction == 1.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_dt = dt_predictions[(dt_predictions.RainTomorrow_index == 0.0) & (dt_predictions.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_dt = dt_predictions[(dt_predictions.RainTomorrow_index == 0.0) & (dt_predictions.prediction == 1.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_dt = dt_predictions[(dt_predictions.RainTomorrow_index == 1.0) & (dt_predictions.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  4236\n",
      "True Negative:  31577\n",
      "False Positive:  1701\n",
      "False Negative:  5396\n",
      "Total:  42910\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive: \",tp_dt)\n",
    "print (\"True Negative: \",tn_dt)\n",
    "print (\"False Positive: \",fp_dt)\n",
    "print (\"False Negative: \",fn_dt)\n",
    "print (\"Total: \",dt_predictions.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_dt = float(tp_dt)/(tp_dt+fp_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_dt = float(tp_dt)/(tp_dt+fn_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7134916624557858\n",
      "Recall:  0.43978405315614616\n"
     ]
    }
   ],
   "source": [
    "print (\"Precision: \",precision_dt)\n",
    "print (\"Recall: \",recall_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score_dt = (2*((precision_dt*recall_dt)/(precision_dt+recall_dt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5441582632153638"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For RandomForestClassifier\n",
    "\n",
    "#### tp_randomforest -> Store True Positive\n",
    "#### tn_randomforest -> Store True Negative\n",
    "#### fp_randomforest -> Store False Positive\n",
    "#### fn_randomforest -> Store False Negative\n",
    "#### precision_randomforest -> Precision \n",
    "#### recall_randomforest -> Recall\n",
    "#### f1score_randomforest -> F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_randomforest = rf_predictions[(rf_predictions.RainTomorrow_index == 1.0) & (rf_predictions.prediction == 1.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_randomforest = rf_predictions[(rf_predictions.RainTomorrow_index == 0.0) & (rf_predictions.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_randomforest = rf_predictions[(rf_predictions.RainTomorrow_index == 0.0) & (rf_predictions.prediction == 1.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_randomforest = rf_predictions[(rf_predictions.RainTomorrow_index == 1.0) & (rf_predictions.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  3857\n",
      "True Negative:  32019\n",
      "False Positive:  1259\n",
      "False Negative:  5775\n",
      "Total:  42910\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive: \",tp_randomforest)\n",
    "print (\"True Negative: \",tn_randomforest)\n",
    "print (\"False Positive: \",fp_randomforest)\n",
    "print (\"False Negative: \",fn_randomforest)\n",
    "print (\"Total: \",rf_predictions.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_randomforest = float(tp_randomforest)/(tp_randomforest+fp_randomforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_randomforest = float(tp_randomforest)/(tp_randomforest+fn_randomforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score_randomforest = (2*((precision_randomforest*recall_randomforest)/(precision_randomforest+recall_randomforest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier - Precision:  0.7539093041438624\n",
      "RandomForestClassifier - Recall:  0.4004360465116279\n",
      "RandomForestClassifier - F1 Score:  0.5230539734201248\n"
     ]
    }
   ],
   "source": [
    "print (\"RandomForestClassifier - Precision: \",precision_randomforest)\n",
    "print (\"RandomForestClassifier - Recall: \",recall_randomforest)\n",
    "print (\"RandomForestClassifier - F1 Score: \",f1score_randomforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For LogisticRegression\n",
    "\n",
    "#### tp_lr -> Store True Positive\n",
    "#### tn_lr -> Store True Negative\n",
    "#### fp_lr -> Store False Positive\n",
    "#### fn_lr -> Store False Negative\n",
    "#### precision_lr -> Precision \n",
    "#### recall_lr -> Recall\n",
    "#### f1score_lr -> F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_lr = lr_predictions[(lr_predictions.RainTomorrow_index == 1.0) & (lr_predictions.prediction == 1.0)].count()\n",
    "tn_lr = lr_predictions[(lr_predictions.RainTomorrow_index == 0.0) & (lr_predictions.prediction == 0.0)].count()\n",
    "fp_lr = lr_predictions[(lr_predictions.RainTomorrow_index == 0.0) & (lr_predictions.prediction == 1.0)].count()\n",
    "fn_lr = lr_predictions[(lr_predictions.RainTomorrow_index == 1.0) & (lr_predictions.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  4102\n",
      "True Negative:  30982\n",
      "False Positive:  2296\n",
      "False Negative:  5530\n",
      "Total:  42910\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive: \",tp_lr)\n",
    "print (\"True Negative: \",tn_lr)\n",
    "print (\"False Positive: \",fp_lr)\n",
    "print (\"False Negative: \",fn_lr)\n",
    "print (\"Total: \",lr_predictions.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_lr = float(tp_lr)/(tp_lr+fp_lr)\n",
    "recall_lr = float(tp_lr)/(tp_lr+fn_lr)\n",
    "f1score_lr = (2*((precision_lr*recall_lr)/(precision_lr+recall_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Precision:  0.6411378555798687\n",
      "LogisticRegression - Recall:  0.4258720930232558\n",
      "LogisticRegression - F1 Score:  0.5117903930131004\n"
     ]
    }
   ],
   "source": [
    "print (\"LogisticRegression - Precision: \",precision_lr)\n",
    "print (\"LogisticRegression - Recall: \",recall_lr)\n",
    "print (\"LogisticRegression - F1 Score: \",f1score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For GBTClassifier\n",
    "\n",
    "#### tp_gbt -> Store True Positive\n",
    "#### tn_gbt -> Store True Negative\n",
    "#### fp_gbt -> Store False Positive\n",
    "#### fn_gbt -> Store False Negative\n",
    "#### precision_gbt -> Precision \n",
    "#### recall_gbt -> Recall\n",
    "#### f1score_gbt -> F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_gbt = gbt_predictions[(gbt_predictions.RainTomorrow_index == 1.0) & (gbt_predictions.prediction == 1.0)].count()\n",
    "tn_gbt = gbt_predictions[(gbt_predictions.RainTomorrow_index == 0.0) & (gbt_predictions.prediction == 0.0)].count()\n",
    "fp_gbt = gbt_predictions[(gbt_predictions.RainTomorrow_index == 0.0) & (gbt_predictions.prediction == 1.0)].count()\n",
    "fn_gbt = gbt_predictions[(gbt_predictions.RainTomorrow_index == 1.0) & (gbt_predictions.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  4758\n",
      "True Negative:  31551\n",
      "False Positive:  1727\n",
      "False Negative:  4874\n",
      "Total:  42910\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive: \",tp_gbt)\n",
    "print (\"True Negative: \",tn_gbt)\n",
    "print (\"False Positive: \",fp_gbt)\n",
    "print (\"False Negative: \",fn_gbt)\n",
    "print (\"Total: \",gbt_predictions.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_gbt = float(tp_gbt)/(tp_gbt+fp_gbt)\n",
    "recall_gbt = float(tp_gbt)/(tp_gbt+fn_gbt)\n",
    "f1score_gbt = (2*((precision_gbt*recall_gbt)/(precision_gbt+recall_gbt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier - Precision:  0.7336931380107942\n",
      "GBTClassifier - Recall:  0.4939784053156146\n",
      "GBTClassifier - F1 Score:  0.5904324626171124\n"
     ]
    }
   ],
   "source": [
    "print (\"GBTClassifier - Precision: \",precision_gbt)\n",
    "print (\"GBTClassifier - Recall: \",recall_gbt)\n",
    "print (\"GBTClassifier - F1 Score: \",f1score_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve the accuracy of the prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Improve prediction accuracy with data:\n",
    "    By getting better quality more data, we can improve our training model and prediction accuracy.\n",
    "To get better and accurate model we can add more data.  It might not be easy to increase the training data in the data science competitions but during doing real life project I would suggest to ask for more data . If it is not possible to get new data we can generate new data. We can augment or permute existing data or use a probabilistic model to generate new data.\n",
    "\n",
    "### 2. Algorithm Tuning\n",
    "    Since the ML algorithms are driven by parameters. The outcome of learning process is influenced by these parameters. The main goal of parameter tuning is to figure out the optimum value for each parameter to bring some improvement of the accuracy of the model. \n",
    "\n",
    "### 3. Ensemble methods\n",
    "    In this technique the predictions  of multiple models are combined to produce better results. This is one of the big areas for improvement after algorithm tuning.  It can be achieved by doing Bagging (Bootstrap Aggregating) or Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference: \n",
    "     Jason Brownlee PhD, May 22, 2019  \n",
    "        https://machinelearningmastery.com/machine-learning-performance-improvement-cheat-sheet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
